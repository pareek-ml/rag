2025-04-12 17:46:52,924 INFO    MainThread:29157 [wandb_setup.py:_flush():67] Current SDK version is 0.19.9
2025-04-12 17:46:52,924 INFO    MainThread:29157 [wandb_setup.py:_flush():67] Configure stats pid to 29157
2025-04-12 17:46:52,924 INFO    MainThread:29157 [wandb_setup.py:_flush():67] Loading settings from /teamspace/studios/this_studio/.config/wandb/settings
2025-04-12 17:46:52,924 INFO    MainThread:29157 [wandb_setup.py:_flush():67] Loading settings from /teamspace/studios/this_studio/rag/src/finetune/wandb/settings
2025-04-12 17:46:52,924 INFO    MainThread:29157 [wandb_setup.py:_flush():67] Loading settings from environment variables
2025-04-12 17:46:52,924 INFO    MainThread:29157 [wandb_init.py:setup_run_log_directory():662] Logging user logs to /teamspace/studios/this_studio/rag/src/finetune/wandb/run-20250412_174652-wyvwrpjq/logs/debug.log
2025-04-12 17:46:52,924 INFO    MainThread:29157 [wandb_init.py:setup_run_log_directory():663] Logging internal logs to /teamspace/studios/this_studio/rag/src/finetune/wandb/run-20250412_174652-wyvwrpjq/logs/debug-internal.log
2025-04-12 17:46:52,924 INFO    MainThread:29157 [wandb_init.py:init():781] calling init triggers
2025-04-12 17:46:52,924 INFO    MainThread:29157 [wandb_init.py:init():786] wandb.init called with sweep_config: {}
config: {'_wandb': {}}
2025-04-12 17:46:52,924 INFO    MainThread:29157 [wandb_init.py:init():809] starting backend
2025-04-12 17:46:52,925 INFO    MainThread:29157 [wandb_init.py:init():813] sending inform_init request
2025-04-12 17:46:52,930 INFO    MainThread:29157 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-04-12 17:46:52,930 INFO    MainThread:29157 [wandb_init.py:init():823] backend started and connected
2025-04-12 17:46:52,932 INFO    MainThread:29157 [wandb_init.py:init():915] updated telemetry
2025-04-12 17:46:53,007 INFO    MainThread:29157 [wandb_init.py:init():939] communicating run to backend with 90.0 second timeout
2025-04-12 17:46:53,328 INFO    MainThread:29157 [wandb_init.py:init():1014] starting run threads in backend
2025-04-12 17:46:53,503 INFO    MainThread:29157 [wandb_run.py:_console_start():2454] atexit reg
2025-04-12 17:46:53,503 INFO    MainThread:29157 [wandb_run.py:_redirect():2306] redirect: wrap_raw
2025-04-12 17:46:53,503 INFO    MainThread:29157 [wandb_run.py:_redirect():2371] Wrapping output streams.
2025-04-12 17:46:53,503 INFO    MainThread:29157 [wandb_run.py:_redirect():2394] Redirects installed.
2025-04-12 17:46:53,506 INFO    MainThread:29157 [wandb_init.py:init():1056] run started, returning control to user process
2025-04-12 17:46:53,507 INFO    MainThread:29157 [wandb_run.py:_config_callback():1327] config_cb None None {'model_name': '/teamspace/studios/this_studio/rag/src/finetune/../../models/base/Llama-3.2-3B-Instruct', 'tokenizer_name': None, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'packing', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'gradient_clipping': False, 'gradient_clipping_threshold': 1.0, 'num_epochs': 3, 'max_train_step': 0, 'max_eval_step': 0, 'num_workers_dataloader': 1, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 1, 'peft_method': 'lora', 'use_peft': True, 'from_peft_checkpoint': '', 'output_dir': '/teamspace/studios/this_studio/rag/src/finetune/models/peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'freeze_LLM_only': False, 'quantization': '4bit', 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': '/teamspace/studios/this_studio/rag/src/finetune/models/fsdp', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': True, 'use_wandb': True, 'save_metrics': True, 'flop_counter': False, 'flop_counter_start': 3, 'use_profiler': False, 'profiler_dir': 'PATH/to/save/profiler/results'}
2025-04-12 17:46:53,508 INFO    MainThread:29157 [wandb_run.py:_config_callback():1327] config_cb None None {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': 'FULL_SHARD', 'hsdp': False, 'sharding_group_size': 0, 'replica_group_size': 0, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
2025-04-12 17:46:56,664 INFO    MsgRouterThr:29157 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
