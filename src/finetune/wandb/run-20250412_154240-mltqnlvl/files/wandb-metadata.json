{
  "os": "Linux-5.15.0-1081-aws-x86_64-with-glibc2.31",
  "python": "CPython 3.12.2",
  "startedAt": "2025-04-12T15:42:40.238924Z",
  "args": [
    "model_name=../../../models/base/Meta-Llama-3-8B",
    "output_dir=../../../models/peft/llama3-sql-lora",
    "dataset=custom_dataset",
    "use_peft=True",
    "run_validation=True",
    "use_wandb=True"
  ],
  "program": "/teamspace/studios/this_studio/rag/src/finetune/finetune.py",
  "codePath": "src/finetune/finetune.py",
  "git": {
    "remote": "https://github.com/pareek-ml/rag.git",
    "commit": "c19b05a452802851d42c94bbac400b75acbe54f3"
  },
  "email": "yash.pareek@usi.ch",
  "root": "/teamspace/studios/this_studio/rag/src/finetune",
  "host": "ip-10-192-12-212",
  "executable": "/home/zeus/miniconda3/envs/cloudspace/bin/python",
  "codePathLocal": "finetune.py",
  "cpu_count": 8,
  "cpu_count_logical": 16,
  "gpu": "NVIDIA L4",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "589427720192",
      "used": "94780723200"
    }
  },
  "memory": {
    "total": "64919932928"
  },
  "cpu": {
    "count": 8,
    "countLogical": 16
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA L4",
      "memoryTotal": "24152899584",
      "cudaCores": 7424,
      "architecture": "Ada"
    }
  ],
  "cudaVersion": "12.2"
}